# -*- coding: utf-8 -*-
"""Ecocnomía Circular.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TLsH40EaVazpxNndR8h2ugCyffLoDXsZ
"""

# streamlit_app_economia_circular_mypymes_optimized.py
# App optimizada: Economía circular, polos de desarrollo e incremento de créditos a MiPyMEs
# Requisitos: streamlit, pandas, numpy, scikit-learn, plotly

import streamlit as st
import pandas as pd
import numpy as np
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
import plotly.express as px

st.set_page_config(layout="wide", page_title="MiPyME Circular & Crédito (Optimizada)")

st.title("MiPyME Conecta: Economía Circular, Polos de Desarrollo y Crédito (Optimizada)")
st.markdown(
    "Versión optimizada: caché para datos y modelo, menos recálculos al mover sliders, y entrenamiento una sola vez por dataset."
)

# --- Sidebar ---
st.sidebar.header("Carga de datos / Parámetros")
uploaded_file = st.sidebar.file_uploader(
    "Sube CSV de MiPyMEs (columnas sugeridas: id, estado, sector, ventas, empleados, lider_mujer(0/1), recicla_pct, digital_score, factura_e(0/1), ventas_online_pct, credito_actual(0/1))",
    type=["csv"]
)
use_sample = False
if uploaded_file is None:
    use_sample = st.sidebar.checkbox("Usar datos de ejemplo (rápido)", value=True)

weights = {
    'circular': st.sidebar.slider('Peso: Economía Circular en índice', 0.0, 1.0, 0.4),
    'digital': st.sidebar.slider('Peso: Digitalización en índice', 0.0, 1.0, 0.3),
    'formal': st.sidebar.slider('Peso: Formalidad / facturación', 0.0, 1.0, 0.2),
    'gender': st.sidebar.slider('Peso: Perspectiva de género (favor mujeres)', 0.0, 1.0, 0.1)
}

st.sidebar.markdown("---")
st.sidebar.header("Simulador de políticas")
capacitacion = st.sidebar.slider("% MiPyMEs que reciben capacitación digital (incremento)", 0, 50, 10)
credit_access_increase = st.sidebar.slider("Meta anual adicional de acceso a crédito (%)", 0.0, 10.0, 3.5)

# --- Data load / sample generation (cached) ---
@st.cache_data
def generate_sample(n=2000, seed=42):
    np.random.seed(seed)
    estados = [
        'CDMX','Jalisco','Nuevo León','Puebla','Oaxaca','Veracruz','Chiapas','Yucatán','Guanajuato','Baja California'
    ]
    sectores = ['Manufactura','Comercio','Servicios','Agro']
    df = pd.DataFrame({
        'id': np.arange(n),
        'estado': np.random.choice(estados, n),
        'sector': np.random.choice(sectores, n),
        'ventas': np.round(np.random.lognormal(mean=10, sigma=1, size=n)),
        'empleados': np.random.poisson(5, n),
        'lider_mujer': np.random.binomial(1, 0.35, n),
        'recicla_pct': np.round(np.random.beta(2,5,n),2),
        'digital_score': np.round(np.random.beta(2,2,n),2),
        'factura_e': np.random.binomial(1, 0.5, n),
        'ventas_online_pct': np.round(np.random.beta(1.5,4,n),2),
        'credito_actual': np.random.binomial(1, 0.28, n)
    })
    # create a synthetic 'prob_credit' increasing with digital_score, factura_e, ventas, lider_mujer
    df['prob_credit'] = (0.2*df['digital_score'] + 0.25*df['factura_e'] + 0.000001*df['ventas'] + 0.15*df['empleados'] + 0.05*df['lider_mujer'] + 0.1*df['recicla_pct'])
    df['prob_credit'] = (df['prob_credit'] - df['prob_credit'].min())/(df['prob_credit'].max()-df['prob_credit'].min())
    df['credito_actual'] = (df['prob_credit'] > np.quantile(df['prob_credit'], 0.72)).astype(int)
    return df.drop(columns=['prob_credit'])

@st.cache_data
def load_base_data(uploaded_file):
    if uploaded_file is None:
        return generate_sample()
    else:
        # read csv uploaded by user
        df = pd.read_csv(uploaded_file)
        # basic cleaning defaults (add missing cols with defaults if necessary)
        expected_cols = ['id','estado','sector','ventas','empleados','lider_mujer','recicla_pct','digital_score','factura_e','ventas_online_pct','credito_actual']
        for c in expected_cols:
            if c not in df.columns:
                # add reasonable default / placeholder
                if c == 'id':
                    df[c] = np.arange(len(df))
                elif c in ['ventas','empleados','lider_mujer','factura_e','credito_actual']:
                    df[c] = 0
                else:
                    df[c] = 0.0
        return df[expected_cols]  # ensure order

df_base = load_base_data(uploaded_file)

# --- Compute indices (cached per df + weights) ---
@st.cache_data
def compute_indices(df, weights):
    df2 = df.copy()
    df2['score_circular'] = (df2['recicla_pct'] + df2['ventas_online_pct'])/2
    df2['score_digital'] = df2['digital_score']
    df2['score_formal'] = df2['factura_e']
    df2['score_gender'] = df2['lider_mujer']
    wsum = weights['circular'] + weights['digital'] + weights['formal'] + weights['gender']
    if wsum == 0:
        wsum = 1
    df2['IIC'] = (
        weights['circular']*df2['score_circular'] +
        weights['digital']*df2['score_digital'] +
        weights['formal']*df2['score_formal'] +
        weights['gender']*df2['score_gender']
    )/wsum
    return df2

# compute df used in UI (this depends on weights, but base data generation won't rerun)
df = compute_indices(df_base, weights)

st.subheader("Datos cargados / de ejemplo")
st.dataframe(df.head(10))

# --- Aggregations & plots (cached to avoid recalculations repetidas) ---
@st.cache_data
def compute_state_agg(df):
    return df.groupby('estado').agg({'IIC':'mean','credito_actual':'mean','id':'count'}).reset_index().rename(columns={'id':'n_empresas'})

state_agg = compute_state_agg(df)

st.subheader("Resumen nacional")
col1, col2 = st.columns([2,1])
with col1:
    fig = px.histogram(df, x='IIC', nbins=30, title='Distribución del Índice de Integración Circular (IIC)')
    st.plotly_chart(fig, use_container_width=True)

with col2:
    avg_iic = df['IIC'].mean()
    pct_credit = df['credito_actual'].mean()*100
    st.metric('IIC promedio (0-1)', f"{avg_iic:.3f}")
    st.metric('% MiPyMEs con crédito', f"{pct_credit:.2f}%")

st.subheader('Mapa / Polos de Desarrollo (por estado)')
fig2 = px.scatter(state_agg, x='n_empresas', y='IIC', size='n_empresas', hover_name='estado', color='credito_actual', title='Estados: tamaño del cluster vs IIC (color=porcentaje con crédito)')
st.plotly_chart(fig2, use_container_width=True)

# Highlight potential polos: high IIC and high firms (cached)
@st.cache_data
def top_polos(state_agg, topn=5):
    polos = state_agg.sort_values(['IIC','n_empresas'], ascending=False).head(topn)
    return polos

polos = top_polos(state_agg)
st.markdown('**Polos candidatos (alto IIC + volumen):**')
st.table(polos)

# --- Modelo predictivo: entrenamiento (cacheado por dataset) ---
# Features used for the model (must exist in df_base)
features = ['ventas','empleados','recicla_pct','digital_score','factura_e','ventas_online_pct','lider_mujer']

def prepare_X_y_for_training(df):
    X = df[features].copy()
    X['ventas_log'] = np.log1p(X['ventas'])
    X = X.drop(columns=['ventas'])
    y = df['credito_actual']
    return X, y

X_full, y_full = prepare_X_y_for_training(df_base)

# compute a simple data hash to let cache invalidate when dataset changes
@st.cache_data
def compute_data_hash(df, cols):
    # Use pandas util hash for the selected columns (fast and sensitive to content changes)
    try:
        h = pd.util.hash_pandas_object(df[cols], index=True).sum()
        return int(h)
    except Exception:
        # fallback: shape + sum of numeric columns
        return int(df[cols].shape[0] + df[cols].select_dtypes(include=[np.number]).sum().sum())

data_hash = compute_data_hash(df_base, features)

@st.cache_resource
def train_model_cached(df_hash, X_df, y_ser):
    """
    Entrena y devuelve: scaler, clf, acc, feat_imp_df
    Nota: st.cache_resource requiere que el primer argumento (df_hash) cambie cuando el dataset cambia.
    Para evitar pasar dataframes grandes como parámetros al caché, enviamos una copia pequeña (X_df, y_ser).
    """
    # Prepare arrays
    X_train, X_test, y_train, y_test = train_test_split(X_df, y_ser, test_size=0.25, random_state=42)
    scaler = StandardScaler()
    X_train_s = scaler.fit_transform(X_train)
    X_test_s = scaler.transform(X_test)

    # MLP con early stopping y menos iteraciones para rapidez
    clf = MLPClassifier(hidden_layer_sizes=(32,16), max_iter=200, early_stopping=True, random_state=42)
    clf.fit(X_train_s, y_train)

    y_pred = clf.predict(X_test_s)
    acc = accuracy_score(y_test, y_pred)

    # feature importance approximation
    coefs = np.mean(np.abs(clf.coefs_[0]), axis=1)
    feat_names = X_df.columns.tolist()
    feat_imp = pd.DataFrame({'feature': feat_names, 'coef_abs_mean': coefs}).sort_values('coef_abs_mean', ascending=False)

    return scaler, clf, acc, feat_imp

# train (cached) - show spinner to user
with st.spinner("Entrenando modelo (solo la primera vez por dataset) — esto puede tardar unos segundos..."):
    scaler, clf, acc, feat_imp = train_model_cached(data_hash, X_full, y_full)

st.subheader('Modelo predictivo: Probabilidad de acceso a crédito (red neuronal)')
st.write(f"Accuracy (test): {acc:.3f}")
st.table(feat_imp)

# --- Interactive: evaluación de una MiPyME individual (usa el modelo cacheado) ---
st.subheader('Evalúa una MiPyME (individual)')
with st.form('eval_form'):
    st.write('Rellena los datos para obtener probabilidad de crédito')
    s_estado = st.selectbox('Estado', df['estado'].unique())
    s_sector = st.selectbox('Sector', df['sector'].unique())
    s_ventas = st.number_input('Ventas (MXN anual, aproximado)', value=1000000)
    s_empleados = st.number_input('Número de empleados', value=5)
    s_recicla = st.slider('Proporción de actividades circulares (0-1)', 0.0, 1.0, 0.1)
    s_digital = st.slider('Puntaje digital (0-1)', 0.0, 1.0, 0.3)
    s_factura = st.selectbox('Factura electrónica (0/1)', [0,1])
    s_ventas_online = st.slider('Ventas online (0-1)', 0.0, 1.0, 0.0)
    s_lider_mujer = st.selectbox('Liderazgo femenino (0/1)', [0,1])
    submitted = st.form_submit_button('Evaluar')
    if submitted:
        x_in = pd.DataFrame({
            'ventas':[s_ventas],
            'empleados':[s_empleados],
            'recicla_pct':[s_recicla],
            'digital_score':[s_digital],
            'factura_e':[s_factura],
            'ventas_online_pct':[s_ventas_online],
            'lider_mujer':[s_lider_mujer]
        })
        x_in['ventas_log'] = np.log1p(x_in['ventas'])
        x_in = x_in.drop(columns=['ventas'])
        # ensure column order matches training
        x_in = x_in[X_full.columns]
        x_in_s = scaler.transform(x_in)
        prob = clf.predict_proba(x_in_s)[0,1]
        st.success(f'Probabilidad estimada de acceder a crédito: {prob:.2%}')

# --- Simulador de impacto en acceso a crédito ---
st.subheader('Simulador: impacto de políticas y meta anual')

baseline_pct = df['credito_actual'].mean()
st.write(f'Porcentaje base de MiPyMEs con crédito: {baseline_pct:.2%}')

# Policy effects: simple linear model: cada 10% de capacitacion -> +x% acceso
policy_effect_per_10 = 0.015  # cada 10pp de capacitación genera +1.5pp en acceso a crédito
policy_effect = (capacitacion/10.0)*policy_effect_per_10
projected_pct_after_policy = baseline_pct + policy_effect
st.write(f'Proyección después de política (capacitación {capacitacion}%): {projected_pct_after_policy:.2%}')

target_increase = credit_access_increase/100.0
st.write(f'Meta anual adicional solicitada: {credit_access_increase:.2f}%')

meets_target = (projected_pct_after_policy - baseline_pct) >= target_increase
if meets_target:
    st.success(f'Con la política seleccionada se alcanza o supera la meta anual de {credit_access_increase:.2f}%')
else:
    st.warning('La política seleccionada NO alcanza la meta anual. Ajusta parámetros o añade medidas complementarias.')

# Multi-year projection (lightweight)
years = st.slider('Años de proyección', 1, 10, 5)
proj = []
current = baseline_pct
for t in range(1, years+1):
    current = current * (1 + target_increase) + policy_effect
    proj.append({'year': t, 'pct_with_credit': current})
proj_df = pd.DataFrame(proj)
fig3 = px.line(proj_df, x='year', y='pct_with_credit', title='Proyección multi-año de acceso a crédito')
st.plotly_chart(fig3, use_container_width=True)

# --- Recomendaciones finales automatizadas ---
st.subheader('Recomendaciones (automatizadas)')
rec = []
if avg_iic < 0.4:
    rec.append('- Promover programas de digitalización y facturación electrónica.')
if df['lider_mujer'].mean() < 0.4:
    rec.append('- Programas focalizados para MiPyMEs lideradas por mujeres (acceso a microcréditos y capacitación).')
if df['recicla_pct'].mean() < 0.15:
    rec.append('- Incentivos para adoptar prácticas circulares (recompensas fiscales, certificaciones).')
rec.append('- Crear incentivos para formar polos locales (clusters) donde exista masa crítica de MiPyMEs con IIC alta.')

for r in rec:
    st.write(r)

st.markdown('---')
st.caption('Versión optimizada: el modelo y parámetros son ilustrativos. Para producción se requiere validación y datos administrativos.')